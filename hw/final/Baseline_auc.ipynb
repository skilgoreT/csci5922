{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "from __future__ import print_function\n",
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the file\n",
    "filepath = \"student_vectors_n_task_10_n_limit_10000.json\"\n",
    "student_vectors = json.load(open(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing a mapping from qual_id and ccssm to one hot representation\n",
    "\n",
    "# collect all qual_ids, ccssm_labels, task_ids in separate lists\n",
    "all_qual_ids = []\n",
    "all_ccssm_labels = []\n",
    "all_task_ids = []\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        all_qual_ids.append(j['qual_id'])\n",
    "        all_ccssm_labels.append(j['ccssm'])\n",
    "        all_task_ids.append(j['task_id'])\n",
    "\n",
    "# make a set of unique values from the above lists\n",
    "unique_ids = set(all_qual_ids)\n",
    "unique_labels = set(all_ccssm_labels)\n",
    "unique_tasks = set(all_task_ids)\n",
    "# print(\"Number of unique labels in this dataset \" + str(len(unique_labels))) #unique labels\n",
    "# print(\"Number of unique lessons/tasks in this dataset \"+str(len(unique_tasks))) #unique lessons\n",
    "# print(\"Number of unique questions in this dataset \"+str(len(unique_ids))) #this is the length of bit vector (number of unique qual_ids)\n",
    "\n",
    "# generate vectors to give to fit_transform in multilabelbinarizer to further generate unique 1-hot encoding\n",
    "transform_ids = []\n",
    "for i in unique_ids:\n",
    "    transform_ids.append([i])\n",
    "\n",
    "transform_labels = []\n",
    "for i in unique_labels:\n",
    "    transform_labels.append([i])\n",
    "    \n",
    "# generate dictionary that maps labels and qual_ids to their respective 1-hot encoding\n",
    "enc = MultiLabelBinarizer()\n",
    "qual_ids_1hot = (enc.fit_transform(transform_ids)).astype(float)\n",
    "qual_ids_classes = enc.classes_\n",
    "qual_ids_dict = dict(zip(unique_ids, qual_ids_1hot))\n",
    "labels_1hot = enc.fit_transform(transform_labels).astype(float)\n",
    "labels_classes = enc.classes_\n",
    "labels_dict = dict(zip(unique_labels,labels_1hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52209\n"
     ]
    }
   ],
   "source": [
    "#preparing a mapping from qual_id and ccssm to normalized frequency distribution\n",
    "freq_dist = {}\n",
    "total_occ = {}\n",
    "total_interactions = 0\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        total_interactions += 1\n",
    "        if j['qual_id'] in total_occ:\n",
    "            total_occ[j['qual_id']] += 1\n",
    "        else:\n",
    "            total_occ[j['qual_id']] = 1\n",
    "        if j['ccssm'] in total_occ:\n",
    "            total_occ[j['ccssm']] += 1\n",
    "        else:\n",
    "            total_occ[j['ccssm']] = 1\n",
    "        if j['correct'] == True:\n",
    "            if j['qual_id'] in freq_dist:\n",
    "                freq_dist[j['qual_id']] += 1\n",
    "            else:\n",
    "                freq_dist[j['qual_id']] = 1\n",
    "            if j['ccssm'] in freq_dist:\n",
    "                freq_dist[j['ccssm']] += 1\n",
    "            else:\n",
    "                freq_dist[j['ccssm']] = 1\n",
    "        if j['correct'] == False: #what if all occurences were answered incorrectly\n",
    "            if j['qual_id'] not in freq_dist:\n",
    "                freq_dist[j['qual_id']] = 0\n",
    "            if j['ccssm'] not in freq_dist:\n",
    "                freq_dist[j['ccssm']] = 0\n",
    "# print(freq_dist)\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(total_occ)\n",
    "# for i in freq_dist:\n",
    "#     if freq_dist[i] != total_occ[i]:\n",
    "#         print(i)\n",
    "#         print(freq_dist[i])\n",
    "#         print(total_occ[i])\n",
    "#         print(\"\\n\")\n",
    "for i in freq_dist:\n",
    "    freq_dist[i] = float(freq_dist[i]) / float(total_occ[i])\n",
    "    \n",
    "print(total_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a vector where we place the frequency of a qual_id/ccssm at the position of the qual_id/ccssm in the vector.\n",
    "y_vector = np.zeros([len(unique_labels) + len(unique_ids)])\n",
    "y_vector_qual = np.zeros([len(unique_ids)])\n",
    "y_vector_ccssm = np.zeros([len(unique_labels)])\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        id_pos = np.argmax(qual_ids_dict[j['qual_id']])\n",
    "        label_pos = np.argmax(labels_dict[j['ccssm']]) + len(unique_ids)\n",
    "        if(y_vector_qual[id_pos] == 0.0):\n",
    "            y_vector_qual[id_pos] = freq_dist[j['qual_id']]\n",
    "        if(y_vector_ccssm[label_pos-len(unique_ids)] == 0.0):\n",
    "            y_vector_ccssm[label_pos-len(unique_ids)] = freq_dist[j['ccssm']]\n",
    "        if(y_vector[id_pos] == 0.0):\n",
    "            y_vector[id_pos] = freq_dist[j['qual_id']]\n",
    "        if(y_vector[label_pos] == 0.0):\n",
    "            y_vector[label_pos] = freq_dist[j['ccssm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243\n"
     ]
    }
   ],
   "source": [
    "# prepare labels array of size: [total_interactions, len(unique_labels) + len(unique_ids)]\n",
    "# but total_interactions should not take into account \n",
    "# first counting cases with effective interaction\n",
    "# that too only in the last question of a student's interaction\n",
    "index = 0\n",
    "flag = False\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        pass\n",
    "    if(j['correct'] == True):\n",
    "        #correct in first try\n",
    "        index += 1\n",
    "    elif(j['correct'] == False and j['second_try'] == True):\n",
    "        #false even after second try\n",
    "        index += 1\n",
    "print(index)\n",
    "effective_interactions = index\n",
    "y_tensor = np.zeros([effective_interactions, len(unique_labels) + len(unique_ids)])\n",
    "y_tensor_qual = np.zeros([effective_interactions, len(unique_ids)])\n",
    "y_tensor_ccssm = np.zeros([effective_interactions, len(unique_labels)])\n",
    "\n",
    "index = 0\n",
    "flag = False\n",
    "for i in student_vectors:\n",
    "    for j in student_vectors[i]:\n",
    "        pass\n",
    "    if(j['correct'] == True):\n",
    "        #correct in first try\n",
    "        a = qual_ids_dict[j['qual_id']]\n",
    "        b = labels_dict[j['ccssm']]\n",
    "        temp = np.append(a, b)\n",
    "        y_tensor[index] = temp\n",
    "        y_tensor_qual[index] = a\n",
    "        y_tensor_ccssm[index] = b\n",
    "        index += 1\n",
    "    elif(j['correct'] == False and j['second_try'] == True):\n",
    "        a = qual_ids_dict[j['qual_id']]\n",
    "        b = labels_dict[j['ccssm']]\n",
    "        temp = np.append(a, b)\n",
    "        #temp = temp * (1.0/3.0)\n",
    "        temp = temp * (0.0)\n",
    "        y_tensor[index] = temp\n",
    "        y_tensor_qual[index] = a * 0.0\n",
    "        y_tensor_ccssm[index] = b * 0.0\n",
    "        index += 1\n",
    "\n",
    "# prepare predictions array of size: [effective_interactions, len(unique_labels) + len(unique_ids)]; \n",
    "pred_tensor = np.zeros([effective_interactions, len(unique_labels) + len(unique_ids)])\n",
    "pred_tensor_qual = np.zeros([effective_interactions, len(unique_ids)])\n",
    "pred_tensor_ccssm = np.zeros([effective_interactions, len(unique_labels)])\n",
    "for i in range(effective_interactions):\n",
    "    pred_tensor[i] = y_vector\n",
    "    pred_tensor_qual[i] = y_vector_qual\n",
    "    pred_tensor_ccssm[i] = y_vector_ccssm\n",
    "    \n",
    "#process y_tensor for auc\n",
    "# for i in range(len(y_tensor)):\n",
    "#     for j in range(len(y_tensor[0])):\n",
    "#         if(y_tensor[i][j] == 1.0):\n",
    "#             print(y_tensor[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = tf.placeholder(tf.float32, [None, len(unique_labels) + len(unique_ids)])\n",
    "# y = tf.placeholder(tf.float32, [None, len(unique_labels) + len(unique_ids)])\n",
    "# if tf.VERSION == '1.3.0':\n",
    "#     auc, opts = tf.metrics.auc(labels = y, predictions = pred, curve='ROC')\n",
    "# elif tf.VERSION == '0.12.1': #summit's tensorflow version API doc: https://www.tensorflow.org/versions/r0.12/api_docs/\n",
    "#     auc, opts = tf.contrib.metrics.streaming_auc(labels = y, predictions = pred, curve='ROC')\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.local_variables_initializer()) #https://github.com/tensorflow/tensorflow/issues/3971\n",
    "#     auc_out,opts_out = sess.run([auc,opts],feed_dict={y: y_tensor, pred: pred_tensor})\n",
    "#     print(auc_out)\n",
    "#     print(opts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc qual: [0.50000024, 0.6011402]\n",
      "tf auc ccssm: [0.16519535, 0.66195381]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "y_true = y_tensor\n",
    "y_scores = pred_tensor\n",
    "y_true_qual = y_tensor_qual\n",
    "y_scores_qual = pred_tensor_qual\n",
    "\n",
    "y_true_ccssm = y_tensor_ccssm\n",
    "y_scores_ccssm = pred_tensor_ccssm\n",
    "# print(\"sklearn auc: {}\".format(roc_auc_score(y_true, y_scores)))\n",
    "\n",
    "import tensorflow as tf\n",
    "auc_qual, update_op_qual = tf.metrics.auc(y_true_qual, y_scores_qual)\n",
    "auc_ccssm, update_op_ccssm = tf.metrics.auc(y_true_ccssm, y_scores_ccssm)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    print(\"tf auc qual: {}\".format(sess.run([auc_qual, update_op_qual])))\n",
    "    print(\"tf auc ccssm: {}\".format(sess.run([auc_ccssm, update_op_ccssm])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
